{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDA Lab Course - Chapter 6 - Personal Mobility Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Introducing Question. What happend here?\n",
    "* Having a look on the track: circles, mountainy region including lifts, track not following any roads, altitude unclear.\n",
    "* Might be ... \n",
    "\n",
    "![Introducing Track: What happend here?](images/header.png)\n",
    "\n",
    "### What are we going to do, briefly?\n",
    "In this course, we gather tools to examine personal mobility tracks in detail and beeing able to make an assumption over specific tracks, behavior and locations and hotspots visited by the recorded person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![s](images/sol.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: GPX-files in python\n",
    "### Theorie of GPX-files is can be found on wikipedia\n",
    "[Link to Wikipedia](https://de.wikipedia.org/wiki/GPS_Exchange_Format)\n",
    "### Working with GPX-Files in Python\n",
    "GPX-data is basically xml-files. To read xml-files, multiple apporaches exist in python but only few of them are feasible for gpx-files.\n",
    "In this lab course we want to use the python-library **gpxpy** to read in the files since it *understands* the gpx format natively, i.e., it is interpreting the xml-structure the gpx-way.\n",
    "\n",
    "There are 2 versions of the GPX-format. Version 1.0 was released in 2002, while version 1.1 followed in 2004. The attribute *speed* is not existing in the newer GPX1.1 and can only be saved using extensions. \n",
    "Geo-data is saved in the GPX-file in one of the following ways:\n",
    "* Waypoint: single waypoint or one GPS-point.\n",
    "* Route: sorded list of waypoints which describe a route.\n",
    "* Track: sorted list of points which form an line. This type is typically returned by gps-recorders.\n",
    "\n",
    "Additionally to the geo-information, GPX can save data in attributes, e.g., **ele** for elevation, **time** for a timestamp or **desc** for a description.\n",
    "Gpxpy can read and write all three types of data.\n",
    "Since typically *tracks* are saved, we going to have a look into reading a gpx-file which contains tracks. First, we start opening the GPX-file. This is done via the standard function *open()* from python. Gpxpy is not needed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpx_file = open(\"data/Gleitschirm.gpx\", 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to parse the content of the file, and get a gpxpy object back. For doing this, we first need to import the gpxpy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpxpy\n",
    "gpx = gpxpy.parse(gpx_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have read in the file and parsed it into the gpxpy structure, we can access the elements. In this case, we loop over all the tracks in the file. For getting all the points, we need to look into all tracks, then look into all segments and finally can access the points. In this example, we save the lat/lon/time values of the points to single lists and additionally print out the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = []\n",
    "longitude=[]\n",
    "time = []\n",
    "\n",
    "for track in gpx.tracks:\n",
    "    for segment in track.segments:\n",
    "        for point in segment.points:\n",
    "            longitude.append(point.longitude)\n",
    "            latitude.append(point.latitude)\n",
    "            time.append(point.time)\n",
    "            print('{} Point at ({},{}). Elevation: {} m'.format(point.time, point.latitude, point.longitude, point.elevation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step, we can save the points into a GeoDataFrame for further analysis. To accomplish this, GeoPandas uses the *gpd.points_from_xy(long, lat)* method to read in the raw lat/lon lists we saved previously. The time vector is used as an index. The start *gdf.head()* of the resulting GeoPandasDataFrame is then printed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "geo_df = gpd.GeoDataFrame(geometry=gpd.points_from_xy(longitude, latitude), index=time)\n",
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: GPS-File Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1: GPX-File import function\n",
    "In order to analyze the recorded profiles, we need the functionality to read GPX-data. Write a function, that reads in the GPX file and returns a GeoDataFrame. Please sort the GeoDataFrame after `time` set the timestamps as index and and put `latitude`/`longitude` as a Point in the `geometry` property of the GeoDataFrame. Add also the `elevation` info to the GeoDatyFrame.\n",
    "________________________\n",
    "\n",
    "#### Signature of the function\n",
    "`gdf_raw = gpx_importer(gpx_file)`\n",
    "\n",
    "**Inputs**: `gpx_file`: String containing a path to the GPX file\n",
    "\n",
    "**Returns:** `gdf_raw`: GeoDataFrame containing `latitude`, `longitute`, `elevation` data and `time` set as index\n",
    "________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpxpy\n",
    "import geopy\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "def gpx_importer(gpx_file):\n",
    "    \n",
    "    # Preallocation of arrays to append the extracted data\n",
    "    latitude = []\n",
    "    longitude = []\n",
    "    elevation = []\n",
    "    time=[]\n",
    "    \n",
    "    # Open the handed over 'gpx_file' and parse data in by using the gpxpy.parse() function\n",
    "    gpx_data = None\n",
    "    # INSERT CODE HERE | BEGIN\n",
    "    #<<solution>>\n",
    "    gpx_fh = open(gpx_file, 'r')\n",
    "    gpx_data = gpxpy.parse(gpx_fh)\n",
    "    #<</solution>>\n",
    "    # INSERT CODE HERE | END\n",
    "    \n",
    "    # Looping over data to access data regarding 'latitude', 'longitude', 'elevation' and 'time'\n",
    "    # Hint: You may want to use a nested loop over 'tracks' --> 'segments' --> 'points' and use the .append() \n",
    "    # function to append the obtain data to the above preallocated arrays.\n",
    "    # Hint: You can, e.g., acces the data of a 'point' regarding 'latitude' with point.latitude\n",
    "    # INSERT CODE HERE | BEGIN\n",
    "    #<<solution>>\n",
    "    for track in gpx_data.tracks:\n",
    "        for segment in track.segments:\n",
    "            for point in segment.points:\n",
    "                latitude.append(point.latitude)\n",
    "                longitude.append(point.longitude)\n",
    "                elevation.append(point.elevation)\n",
    "                time.append(point.time)\n",
    "    #<</solution>>\n",
    "    # INSERT CODE HERE | END\n",
    "                \n",
    "    # Based on your extracted data, initialize a GeoDataFrame with 'geometry' and 'elevation' columns,\n",
    "    # while the 'time' is set as index. Sort your GeoDataFrame by 'time'\n",
    "    # Hint: How can you derive 'geometry' points from xy? You may also want to make use of the following\n",
    "    # functions: gdf.sort_values(by=) and gdf.set_index()\n",
    "    gdf_raw = None\n",
    "    # INSERT CODE HERE | BEGIN\n",
    "    #<<solution>>\n",
    "    gdf_raw = gpd.GeoDataFrame(\n",
    "        {\"elevation\":elevation, \"time\":time},\n",
    "        geometry=gpd.points_from_xy(longitude, latitude)).sort_values(by=\"time\").set_index(\"time\")\n",
    "    #<</solution>>\n",
    "    # INSERT CODE HERE | END   \n",
    "    \n",
    "    return gdf_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your function\n",
    "Test your function with a GPX file (`GPX_FILE = \"rawdata/Gleitschirm.gpx\"`, given in the cell below). Please print out the `gdf.head()` of the GeoDataFrame. Make sure to test the gpx_importer in a new cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the file you want to read to validate the gpx_importer(gpx_file) function\n",
    "GPX_FILE = \"data/Gleitschirm.gpx\"\n",
    "\n",
    "# Read 'GPX_FILE' and show the head of the data. Did your implemented function work correctly?\n",
    "my_mobility_data_single_file = None\n",
    "# INSERT CODE HERE | BEGIN\n",
    "#<<solution>>\n",
    "my_mobility_data_single_file = gpx_importer(GPX_FILE)\n",
    "my_mobility_data_single_file.head()\n",
    "#<</solution>>\n",
    "# INSERT CODE HERE | END  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2: Multi-GPX-File import function\n",
    "As you propably noticed, your GPX-logging app may produces more then one file. The Android App [GPSLogger](https://play.google.com/store/apps/details?id=com.mendhak.gpslogger&hl=de) for example, saves each day in a seperate file. To handle these many files, we need a multi-file importer. Luckily, we already can import one GPX-file, so it should be easy to apply this function to several files, right? Create a new function importing multiple GPX-files!\n",
    "\n",
    "Use the following technologies/approach in the function:\n",
    "* Use the python standard package `glob` to read in all the files inside a folder\n",
    "* For-loop over all found, valid files\n",
    "* Use the previously defined function `gpx_importer(GPX_FILE)` to read in a single GPX-file\n",
    "* Appending the single, imported files to a common GeoDataFrame\n",
    "________________________\n",
    "\n",
    "### Signature of the function\n",
    "`imported_files = gpx_multi_importer(folder)`\n",
    "\n",
    "**Inputs**: `folder_path`: Path to a folder containing GPX-files\n",
    "\n",
    "**Returns:** `imported_files`: Ordered GeoDataFrame of all GPX-files in the input folder path\n",
    "________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you need to import a new library before you can run the code below?\n",
    "# INSERT CODE HERE | BEGIN\n",
    "#<<solution>>\n",
    "import glob\n",
    "#<</solution>>\n",
    "# INSERT CODE HERE | END \n",
    "\n",
    "def gpx_multi_importer(folder_path):\n",
    "    \n",
    "    # The glob.glob function allows you to store files (in this case all files with \"*.gpx\" ending) in a folder object\n",
    "    gpx_file_list = glob.glob(folder_path + \"*.gpx\")\n",
    "    \n",
    "    # Use this GeoDataFrame to append the the separated files of the folder object 'gpx_file_list'\n",
    "    imported_files = gpd.GeoDataFrame()\n",
    "    \n",
    "    # Loop over the 'gpx_files' in 'gpx_file_list' and append obtained data to the above initialized 'imported_files'\n",
    "    # in sorted manner. You might use an intermediate step to read 'gpx_file' using your gpx_importer(gpx_file) function.\n",
    "    # Hint: There is an argument 'sort=True' for the .append() function available.\n",
    "    # INSERT CODE HERE | BEGIN\n",
    "    #<<solution>>\n",
    "    for gpx_file in gpx_file_list:\n",
    "        res = gpx_importer(gpx_file)\n",
    "        imported_files = imported_files.append(res, sort=True)\n",
    "    #<</solution>>\n",
    "    # INSERT CODE HERE | END \n",
    "    \n",
    "    # Sort the index of your file by using the gdf.sort_index() function\n",
    "    # INSERT CODE HERE | BEGIN\n",
    "    #<<solution>>\n",
    "    imported_files = imported_files.sort_index()\n",
    "    #<</solution>>\n",
    "    # INSERT CODE HERE | END \n",
    "    \n",
    "    return imported_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the function\n",
    "Test the function in a new cell. Use the folder `folder = \"data/lukas_31-7_bis_6-8/\"` as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the path to the folder you want to read to validate the gpx_multi_importer(folder) function\n",
    "folder = \"data/lukas_31-7_bis_6-8/\"\n",
    "\n",
    "# Read all files in 'folder' and show the head of the resulting GeoDataFrame. Did your implemented\n",
    "# function work correctly? You sould see 'time' as index and 'elevation' and 'geometry' (point) as columns.\n",
    "# INSERT CODE HERE | BEGIN\n",
    "#<<solution>>\n",
    "my_mobility_data = gpx_multi_importer(folder)\n",
    "my_mobility_data.head()\n",
    "#<</solution>>\n",
    "# INSERT CODE HERE | END "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 2: Reuse the *calculate_distance()* function\n",
    "In a previous part of the lab course (Chapter 3 - Basic Methods and Visualization) you developed a function to calculate the distance between a pair of lat/lon values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given function: lat_lon_2_m from chapter 3\n",
    "def lat_lon_2_m(latitude_1, longitude_1, latitude_2, longitude_2):\n",
    "    \n",
    "    # Radius of the earth in m\n",
    "    radius_earth = 6371009\n",
    "\n",
    "    d_latitude = np.deg2rad(latitude_2 - latitude_1)\n",
    "    d_longitude = np.deg2rad(longitude_2 - longitude_1)\n",
    "    latitude_1 = np.deg2rad(latitude_1)\n",
    "    latitude_2 = np.deg2rad(latitude_2)\n",
    "\n",
    "    a = (np.sin(d_latitude / 2)) ** 2 + np.cos(latitude_1) * np.cos(latitude_2) * (np.sin(d_longitude / 2)) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    distance = radius_earth * c\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reuse the given function `lat_lon_2_m()` in this place and test the function using the two given points:\n",
    "\n",
    "**Point 1**: (48.5, 11.1)<br>\n",
    "**Point 2**: (48.9, 11.6)\n",
    "\n",
    "The return value should be approx. 57.66 km. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the lat_lon_2_m() function with the given points and print the result\n",
    "# INSERT CODE HERE | BEGIN\n",
    "#<<solution>>\n",
    "d = lat_lon_2_m(*(48.5, 11.1), *(48.9, 11.6)) / 1000\n",
    "print(\"Distance between point 1 and point 2:\", round(d,4), \"km\")\n",
    "#<</solution>>\n",
    "# INSERT CODE HERE | END "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare distance results of several functions\n",
    "Compare this result to the output of the two geopy functions below. Use the above given coordinates as input.\n",
    "* `geopy.distance.great_circle((lat,lon), (lat,lon))` and \n",
    "* `geopy.distance.geodesic((lat,lon), (lat,lon))` <br>\n",
    "[Documentation](https://geopy.readthedocs.io/en/latest/#geopy.distance.great_circle)\n",
    "\n",
    "How would you explain the different return value of `lat_lon_2_m()` and `great_circle()` vs. `geodesic()`? Answer in a short note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to import the geopy.distance functions\n",
    "# INSERT CODE HERE | BEGIN\n",
    "#<<solution>>\n",
    "from geopy.distance import great_circle, geodesic\n",
    "#<</solution>>\n",
    "# INSERT CODE HERE | END \n",
    "\n",
    "# Compare to the results of geopy.distance functions.\n",
    "# Use gc for the great_circle function, gd for the geodesic function\n",
    "gc = None\n",
    "gd = None\n",
    "# INSERT CODE HERE | BEGIN\n",
    "#<<solution>>\n",
    "gc = great_circle((48.5, 11.1), (48.9, 11.6))\n",
    "gd = geodesic((48.5, 11.1), (48.9, 11.6))\n",
    "#<</solution>>\n",
    "# INSERT CODE HERE | END \n",
    "\n",
    "print(\"Great Circle: \", round(gc.km, 4), \"km\")\n",
    "print(\"Geodesic: \", round(gd.km, 4), \"km\")\n",
    "print(\"Difference: \", round(abs(gc.m - gd.m), 2), \"m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3A (given): Speed and Acceleration\n",
    "### Info\n",
    "In Task 3, many functions are given that augment the gps data imported before. Since there is not enough time to implement the functions on your own, they are given. Please look at the specifications of the functions and make yourself familiar with the way the work. Use the dataset *my_mobility_data* you imported with the multi_importer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given function from Chapter 3 - Basic Methods and  Visualization\n",
    "Function that calculates distances between two consectuive points using `lat_lon_2_m` function.\n",
    "________________________\n",
    "#### Signature of the function\n",
    "`distance = calculate_distance(latitude, longitude)`\n",
    "**Inputs**: \n",
    "* `latitude`: Array containing latitude coordinates\n",
    "* `longitude`: Array containing longitude coordinates\n",
    "\n",
    "**Returns**: `distance`: np.array containing distance between all consectuive points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given function from Chapter 3 - Basic Methods and Visualization\n",
    "def calculate_distance(latitude, longitude):\n",
    "    if len(latitude) != len(longitude):\n",
    "        return np.nan\n",
    "    else:\n",
    "        # initialize distance array\n",
    "        distance = np.zeros(len(latitude))\n",
    "        # loop latitude, longitude\n",
    "        for i in range(0, len(latitude) - 1):\n",
    "            # calculate distance between two consecutive points using lat_lon_2_km function\n",
    "            d = lat_lon_2_m(\n",
    "                latitude[i],\n",
    "                longitude[i],\n",
    "                latitude[i + 1],\n",
    "                longitude[i + 1])\n",
    "            # append distance to array\n",
    "            distance[i + 1] = d\n",
    "        return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1 (given): Function that calculates the speed from the GPX-track\n",
    "\n",
    "Function calculates the speed of a GPX-track.<br>\n",
    "Test your function on the GPX-dataset. Add the columns *speed* and *acc* to the input dataframe. <br>\n",
    "\n",
    "#### Signature of the function\n",
    "`speed = calculate_speed_trend(array_distances, array_deltatime)`\n",
    "\n",
    "**Inputs**: \n",
    "* `array_distances`: Distances, calculated by the function *calculate_distance(latitude, longitude)* from (Chapter 3 - Basic Methods and Visualization)\n",
    "* `array_deltatime`: Array of delta time between the timestamps of our input dataset. Use *diff()* to calcualte\n",
    "\n",
    "**Returns**: `speed`: Array containing speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given function from Task 3.1\n",
    "def calculate_speed(array_distances, array_deltatime):\n",
    "    if len(array_distances) != len(array_deltatime):\n",
    "        print(\"input vector length does not match!\")\n",
    "        return np.nan\n",
    "    else:\n",
    "        # preallocate the return variable\n",
    "        speed = [0] * (len(array_distances)-1)\n",
    "        for i in range(0, len(array_distances)-1):\n",
    "            speed[i] = array_distances[i] / array_deltatime[i] * 3.6\n",
    "        # Add entry to acceleration, to have same length as speed\n",
    "        speed = np.append(speed, [0])\n",
    "        return speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2 (given):  Function that calculates the acceleration from the GPX-track\n",
    "\n",
    "Function calculates the acceleration of a speed-signal.<br>\n",
    "Test your function on the GPX-dataset. Add the columns *acc* to the input dataframe. <br>\n",
    "________________________\n",
    "#### Signature of the function\n",
    "`acceleration = calculate_acceleration(speed, array_deltatime)`\n",
    "\n",
    "**Inputs**:\n",
    "* `speed`: Input data, a vector containing speed signals\n",
    "* `array_deltatime`: Array of delta time between the timestamps of our input dataset\n",
    "\n",
    "**Returns**: `acceleration`: Acceleration as array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given function from Task 3.2\n",
    "def calculate_acceleration(speed, array_deltatime):\n",
    "    acceleration = np.diff(speed)\n",
    "    # Add entry to acceleration, to have same length as speed\n",
    "    acceleration = np.append(acceleration, [0]) / array_deltatime\n",
    "    return acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.3 (given): Function that corrects the speed data using acceleration\n",
    "\n",
    "Now that we have a raw speed value and the acceleration from it, we can look for \"unnormal\" accelerations and decide to ignore them as well as the underlying speed value. This function loops through the acceleration vector and checks whether an accerleration value is above a given threshold, e.g., *THRESHOLD_ACC = 10 m/s²*.\n",
    "________________________\n",
    "#### Signature of the function\n",
    "`speed_corr = correct_speed(speed, acceleration, threshold)`\n",
    "\n",
    "**Inputs**: \n",
    "* `speed:` Vector containing speed signal.\n",
    "* `acceleration`: Vector containing the acceleration signal\n",
    "* `threshold`: Int/float representing a threshold, when to \"untrust\" a value\n",
    "\n",
    "**Returns**: `speed_corr`: Corrected speed as array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given function from Task 3.3\n",
    "def correct_speed(speed, acceleration, threshold):\n",
    "    if len(speed) != len(acceleration):\n",
    "        print(\"input vector length does not match!\")\n",
    "        return np.nan\n",
    "    else:\n",
    "        # Initiate the corrected speed vector with the original\n",
    "        speed_corr = np.zeros((len(speed), 1))\n",
    "        # Loop over and replace speeds, if acceleration > threshold\n",
    "        speed_corr = speed\n",
    "        for i in range(0, len(speed)-3):\n",
    "            #speed_corr[i] = speed[i]\n",
    "            if abs(acceleration[i]) > threshold:\n",
    "                #speed_corr[i:i+3] = np.NaN\n",
    "                speed_corr[i-3:i+3] = np.NaN  \n",
    "        return speed_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.4 (given): Function that calculates a moving average of the speed data\n",
    "\n",
    "Function calculates a moving-averaged speed-signal to support later analyses.<br>\n",
    "Add the columns *speed_ma* (Moving averaged speed values) to the input dataframe. <br>\n",
    "Details: [Theory and Implementation of Movingaverages in Python](https://waterprogramming.wordpress.com/2018/09/04/implementation-of-the-moving-average-filter-using-convolution/)\n",
    "________________________\n",
    "#### Signature of the function\n",
    "`ma_values = movingaverage(values, window)`\n",
    "\n",
    "**Inputs**: \n",
    "* `values`: signtal to be averaged\n",
    "* `window`: Window size of the moving-average \n",
    "\n",
    "**Returns**: `ma_values`: Averaged input-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given function from Task 3.4\n",
    "def movingaverage (values, window):\n",
    "    weights = np.repeat(1.0, window)/window\n",
    "    sma = np.convolve(values, weights, 'same')\n",
    "    return sma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3B: Enrich *my_mobility_data* with acceleration and speeds\n",
    "Now, we make use of the given functions from Taks 3A to calculate speed, speed_corrected, moving_averaged_speed (from the speed_corrected) and acc. Augment the `my_mobility_data` DataFrame with the calculated data. <br>\n",
    "\n",
    "### Add the new values to the dataset\n",
    "Name the new columns in the dataframe:\n",
    "- speed_corrected: `my_mobility_data[\"speed_corr\"]`\n",
    "- speed: `my_mobility_data[\"speed\"]`\n",
    "- acc: `my_mobility_data[\"acc\"]`\n",
    "- speed_moving_averaged: `my_mobility_data[\"speed_ma\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "# Given constant to threshold acceleration \n",
    "THRESHOLD_ACC = 10\n",
    "\n",
    "# We calculate the distance and corresponding delta_times of my_mobility_data as you need these\n",
    "# characteristics later on.\n",
    "distances = calculate_distance(my_mobility_data.geometry.y, my_mobility_data.geometry.x) \n",
    "delta_times = my_mobility_data.index.to_series().diff().apply(lambda x: x.total_seconds())\n",
    "\n",
    "# Calculate speed, acceleration and speed_corr\n",
    "# Hint: Make use of the functions given in Task 3A \n",
    "speed = None\n",
    "acc = None\n",
    "speed_corr = None\n",
    "# INSERT CODE HERE | BEGIN\n",
    "#<<solution>>\n",
    "speed = calculate_speed(distances, delta_times)\n",
    "acc = calculate_acceleration(speed, delta_times)\n",
    "speed_corr = correct_speed(speed, acc, THRESHOLD_ACC)\n",
    "#<</solution>>\n",
    "# INSERT CODE HERE | END \n",
    "\n",
    "# Add the new data back into the original GeoDataFrame my_mobility_data,\n",
    "# e.g., speed_corr should be contained in the column my_mobility_data[\"speed_corr\"]\n",
    "# INSERT CODE HERE | BEGIN\n",
    "#<<solution>>\n",
    "my_mobility_data[\"speed_corr\"] = speed_corr\n",
    "my_mobility_data[\"speed\"] = speed\n",
    "my_mobility_data[\"acc\"] = acc\n",
    "#<</solution>>\n",
    "# INSERT CODE HERE | END \n",
    "\n",
    "# Calculation of averaged speed\n",
    "speed_moving_averaged = movingaverage(my_mobility_data['speed_corr'], 15)\n",
    "my_mobility_data[\"speed_ma\"] = speed_moving_averaged\n",
    "\n",
    "# To get more detailed insight on the corrected speed data \"speed_corr\", print the .mean()\n",
    "# and median() values of my_mobility_data[\"speed_corr\"]\n",
    "# INSERT CODE HERE | BEGIN\n",
    "#<<solution>>\n",
    "print(\"Mean speed_corr: {} km/h\".format(round(my_mobility_data[\"speed_corr\"].mean(), 2)))\n",
    "print(\"Median speed_corr: {} km/h\".format(round(my_mobility_data[\"speed_corr\"].median(), 2)))\n",
    "#<</solution>>\n",
    "# INSERT CODE HERE | END "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the new values of the dataset\n",
    "- Plot the corrected speed of the data\n",
    "- Plot the moving averaged speed of the data\n",
    "- Plot the acceleration of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot speed data\n",
    "# INSERT CODE HERE | BEGIN\n",
    "#<<solution>>\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(my_mobility_data[\"speed_corr\"], marker=\"*\", linestyle=\"None\")\n",
    "ax.set_xlabel(\"time\")\n",
    "ax.set_ylabel(\"speed_corr in km/h\")\n",
    "ax.set_title(\"speed_corr\")\n",
    "#<</solution>>\n",
    "# INSERT CODE HERE | END \n",
    "\n",
    "# Plot of speed moving average data\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(my_mobility_data[\"speed_ma\"], marker=\".\")\n",
    "ax.set_xlabel(\"time\")\n",
    "ax.set_ylabel(\"averaged speed in km/h\")\n",
    "ax.set_title(\"Averaged Speed\")\n",
    "\n",
    "# Plot of acceleration data\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(my_mobility_data[\"acc\"], marker=\".\", linestyle=\"None\")\n",
    "ax.set_xlabel(\"time\")\n",
    "ax.set_ylabel(\"acceleration in m/s\")\n",
    "ax.set_title(\"Acceleration\")\n",
    "ax.set_ylim([-500,500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (given): Creating a Dataset with Continous Timestamp\n",
    "The timestamp from the GPX-measurement can have gaps and inconsistent delta-timesteps. We want a dataset which has a linear time without gaps and with a static timestep-size for our further analysis. Missing data needs to be filled with NaNs.\n",
    "\n",
    "We use the following methodology:\n",
    "* Create a new GeoDataFrame `my_mobility_data_cont` with a datetime-index with the desired timestep, e.g., frequency of 10s, 20s or 30s\n",
    "* Use the pandas method `merge_asof()` to merge the original GeoDataFrame with the new, resampled one.\n",
    "\n",
    "After the merge process, we need to reconfigure things a bit. By using the pandas `merge_asof()` method, our GeoDataFrame gets messed up and the geometry attribute is a *pandas.Series* now. We want it to be a *geopandas.GeoSeries*. \n",
    "* To re-convert back to the GeoDataframe, initialize a new GeoDataFrame with the output DataFrame from the merge process as input for the constructor.\n",
    "* As a control to check if everything went right, please plot the `[\"speed_corr\"]` attribute \n",
    "* As a second check, please print the type of the geometry-column like so: *type(myGeoDataFrame.geometry)*. This should produce the following output: `<class 'geopandas.geoseries.GeoSeries'>`\n",
    "\n",
    "Please go through the code below and think throught it. Because of time-contraints, we set this as given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "# Create continous time vector from start to end\n",
    "time_start = my_mobility_data.index[0]\n",
    "time_end = my_mobility_data.index[-1]\n",
    "time_range = pd.date_range(time_start, time_end, freq='30s')\n",
    "\n",
    "# create new dataframe using the time_range as index\n",
    "my_mobility_data_cont = gpd.GeoDataFrame({}, index=time_range)\n",
    "\n",
    "# merge old data into the new frame using merge_asof\n",
    "my_mobility_data_cont = pd.merge_asof(\n",
    "    my_mobility_data_cont, my_mobility_data.sort_index(), left_index=True, right_index=True)\n",
    "\n",
    "# Reconvert to GeoDataFrame again\n",
    "my_mobility_data_cont = gpd.GeoDataFrame(my_mobility_data_cont)\n",
    "\n",
    "# Plot the speed_corr from the continous and resampled dataframe\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(my_mobility_data_cont[\"speed_corr\"])\n",
    "print(\"Length: {}\".format(my_mobility_data_cont.size))\n",
    "print(type(my_mobility_data_cont[\"geometry\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 (given): Plot the GPX File / Data\n",
    "\n",
    "### Info\n",
    "\n",
    "To visualize the data, we want to plot it on a map. Please make yourself comfortable with the class' *folium_plot*, that plots the geometry of the well known `my_mobility_data` onto a map.\n",
    "We use the package [**folium**](https://python-visualization.github.io/folium/) here for mapping.\n",
    "\n",
    "#### Structure of the class\n",
    "\n",
    "**Classname:** folium_plot <br>\n",
    "**Membermethods:**<br>\n",
    "* init()\n",
    "* add_to_folium(GeoDataFrame): Plot GeoDataFrame holding Points as PolyLine to a map\n",
    "* add_many_to_folium(list(GeoDataFrame)) Plot several GeoDataFrames from a list to a map. All in different colors.\n",
    "* add_geojson_to_folium(gdf_poly, tooltip): Plot a GeoDataFrame holding a single geometry object e.g. polygon, circle. This does not work for whole tracks (use add_to_folium, add_many_to_folium for this usecase)\n",
    "* save_map(path_name): Save map as .html document to *path_name*\n",
    "* show_map(): Needs to be the last statement of a cell. Triggers showing the map.\n",
    "\n",
    "### Plot my_mobility_data\n",
    "The code is already given in the cell below the plot-class definition.\n",
    "Make use of the class and plot the *my_mobility_data* dataset using the decribed class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import os\n",
    "\n",
    "# Given: Class to plot geo data into folium maps\n",
    "class folium_plot():\n",
    "    def __init__(self, **kwargs):\n",
    "        \n",
    "        self.width = kwargs.get(\"width\", \"100%\")\n",
    "        self.height = kwargs.get(\"height\", \"600\")\n",
    "        self.location = kwargs.get(\"location\", [48.15, 11.57])\n",
    "        self.f = folium.Figure(width=self.width, height=self.height)\n",
    "        #self.m = folium.Map(location=self.location, tiles='stamentoner', zoom_start=11, crs=\"EPSG4326\").add_to(self.f)\n",
    "        self.m = folium.Map(location=self.location, tiles='stamentoner', zoom_start=11).add_to(self.f)\n",
    "\n",
    "        self.color_map =  ['red', 'blue', 'green', 'purple', 'orange', 'darkred', 'darkblue', 'darkgreen', 'cadetblue', 'pink', 'lightblue', 'lightgreen',\n",
    "                 'gray', 'lightgray']\n",
    "    \n",
    "    # For Points in geometry: adds them as a polyline\n",
    "    def add_to_folium(self, my_mobility_data, color=\"red\", tooltip=\"\"):\n",
    "\n",
    "        # Zip data together in a np-array\n",
    "        data2 = np.array(list(zip(my_mobility_data['geometry'].y, my_mobility_data['geometry'].x)))\n",
    "        folium.PolyLine(data2, color=color, weight=4.5, opacity=1, tooltip=tooltip).add_to(self.m)\n",
    "        return self.m\n",
    "    \n",
    "    # give a list of geodataframes and plot each one as polyline\n",
    "    def add_many_to_folium(self, my_mobility_data_list):\n",
    "        for idx, my_mobility_data in enumerate(my_mobility_data_list):\n",
    "            self.add_to_folium(my_mobility_data, color=self.color_map[idx % len(self.color_map)], tooltip=idx)\n",
    "    \n",
    "    # Add geometry like polygon, point from a geoDataFrame to the map\n",
    "    def add_geojson_to_folium(self, gdf_poly, tooltip=\"\"):\n",
    "        folium.GeoJson(gdf_poly, tooltip=tooltip).add_to(self.m)\n",
    "    \n",
    "    # Add a marker at a given position to the map\n",
    "    def add_marker_to_folium(self, lat, lon, popup=\"\"):\n",
    "        folium.Marker([lon, lat], popup=popup).add_to(self.m)\n",
    "\n",
    "    # save the map to a html-file\n",
    "    def save_map(self, path_name):\n",
    "        self.m.save(os.path.join(path_name))\n",
    "    \n",
    "    # call at the end of the cell: Showing the map\n",
    "    def show_map(self):\n",
    "        return self.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the plot map class to plot the dataset\n",
    "m = folium_plot()\n",
    "m.add_to_folium(my_mobility_data)\n",
    "m.add_marker_to_folium(lon=my_mobility_data.geometry.y[0], lat=my_mobility_data.geometry.x[1], popup=\"start\")\n",
    "m.show_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Basic statistical KPIs\n",
    "For our further analyses, we need a function that calculates and plots statistical kpis for a given dataset.\n",
    "\n",
    "### Task 6.1 (given): Get total distance of track\n",
    "Before comming to the function dealing with the KPIs, we need a helper function: Create a function that calculates the total distance of a dataset. You can re-use the `calculate_distance()` function of Chapter 3 and encapsualte it into the new function.\n",
    "________________________\n",
    "#### Signature of the function\n",
    "`distance = total_distance(my_mobility_data)`\n",
    "\n",
    "**Inputs**: `my_mobility_data`: Dataframe containing the trip\n",
    "\n",
    "**Returns**: `distance`: Total distance of the dataset in **km**\n",
    "________________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_distance(my_mobility_data):\n",
    "    \n",
    "    # Total travel distance, allocated to 0\n",
    "    total_distance = 0\n",
    "    # Calculate vector of disntances between the points\n",
    "    distances = calculate_distance(my_mobility_data.geometry.y, my_mobility_data.geometry.x)\n",
    "    # Sum up vector, divide by 1000 to get km\n",
    "    total_distance = distances.sum() / 1000 \n",
    "    \n",
    "    return total_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.2: Function calculating and plotting KPIs\n",
    "\n",
    "Now that we have all the helper functions ready, we can create the KPIs function. The following KPIs should be calculated and printed / plotted from inside the function:\n",
    "\n",
    "#### KPIs to be printed out:\n",
    "* Total travel distance in km\n",
    "* Total track time: Human readable time representation.\n",
    "* Total track start: Human readable time representation.\n",
    "* Total track end: Human readable time representation.\n",
    "* Total moving time: Human readable time representation. Detect movement by observing the speed-vector. Introduce a adjustable threshold to detect \"zero speed\"\n",
    "* Average travel speed in km/h. Use speed_corr.\n",
    "* Average travel speed, only moving time in km/h. Use speed_corr.\n",
    "* Average elevation of track in m\n",
    "\n",
    "#### KPIs to be plotted:\n",
    "* Histogram of the travel speeds. Use fixed bins in the interval [0,100] km/h with a stepsize of 5 km/h.\n",
    "* Elevation of the track\n",
    "* speed trend of the track (Either speed_ma or speed_corr)\n",
    "________________________\n",
    "#### Signature of the function\n",
    "`dict = statistical_kpis(my_mobility_data)`\n",
    "\n",
    "**Inputs**: `my_mobility_data`: Dataframe containing the trip\n",
    "\n",
    "**Returns**: `{\"av_speed\": av_speed, \"total_distance\": dis}`: Dictionary containing average speed and distance\n",
    "________________________\n",
    "Please make sure that the KPIs are printed/plotted in a way, that they are clearly specified and accompanied by a meaningful unit, e.g., \"Total traveled distance: 3000 km\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of geopy\n",
    "from geopy import distance\n",
    "import geopy\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "# Threshold to detect zero speed\n",
    "THRESHOLD_DETECT_ZERO_SPEED = 0\n",
    "\n",
    "# Function to calculate statistical kpis and plot basic values\n",
    "def statistical_kpis(my_mobility_data):\n",
    "\n",
    "    # Calculate the total track distance in km of the input data 'my_mobility_data' and\n",
    "    # print the result rounded to 2 digits\n",
    "    # Hint: Use the previously introduced function total_distance()\n",
    "    dis = None\n",
    "    # INSERT CODE HERE | BEGIN\n",
    "    #<<solution>>\n",
    "    dis = total_distance(my_mobility_data)\n",
    "    print(\"Total travel distance: {} km,\".format(round(dis, 2)))\n",
    "    #<</solution>>\n",
    "    # INSERT CODE HERE | END \n",
    "    \n",
    "    # Add the index again to my_mobility_data as a column 'time'\n",
    "    my_mobility_data[\"time\"] = my_mobility_data.index\n",
    "    \n",
    "    # Calculate the total track time 'time_delta' by subtracting the end time from the \n",
    "    # start time of my_mobility_data[\"time\"]\n",
    "    time_start = None\n",
    "    time_end = None\n",
    "    time_delta = None\n",
    "    # INSERT CODE HERE | BEGIN\n",
    "    #<<solution>>\n",
    "    time_start = my_mobility_data[\"time\"].iloc[0]\n",
    "    time_end = my_mobility_data[\"time\"].iloc[-1]\n",
    "    time_delta = time_end - time_start\n",
    "    #<</solution>>\n",
    "    # INSERT CODE HERE | END \n",
    "    \n",
    "    # Total track start and end time\n",
    "    print(\"Total track time: {} s. This are {} h,\".format(\n",
    "        time_delta.total_seconds(), round(time_delta.total_seconds() / 3600, 2)))    \n",
    "    print(\"Total track start: {}\".format(time_start))\n",
    "    print(\"Total track end: {}\".format(time_end))\n",
    "\n",
    "    # Calculation of the total moving time (speed higher than 0km/h)\n",
    "    mean_dt = my_mobility_data_cont[\"time\"].diff().mean().total_seconds()\n",
    "    dt_counter = \\\n",
    "        mean_dt*my_mobility_data[\"speed_corr\"].loc[my_mobility_data[\"speed_corr\"] > THRESHOLD_DETECT_ZERO_SPEED].size\n",
    "    print(\"Total moving time: {} s. This are {} h\".format(round(dt_counter, 2), round(dt_counter / 3600, 2)))\n",
    "\n",
    "    # Calculate the average travel speed, based on the corrected speed my_mobility_data[\"speed_corr\"]\n",
    "    # Hint: You may want to use the np.nanmean() function which calculates the mean() of all non-nan values\n",
    "    av_speed = None\n",
    "    # INSERT CODE HERE | BEGIN\n",
    "    #<<solution>>\n",
    "    av_speed = np.nanmean(my_mobility_data[\"speed_corr\"])\n",
    "    #<</solution>>\n",
    "    # INSERT CODE HERE | END \n",
    "    print(\"Average travel speed: {} km/h\".format(round(av_speed, 2)))\n",
    "    \n",
    "    # Average travel speed, but only moving time\n",
    "    av_speed = \\\n",
    "        np.nanmean(my_mobility_data[\"speed_corr\"].loc[my_mobility_data[\"speed_corr\"] > THRESHOLD_DETECT_ZERO_SPEED])\n",
    "    print(\"Average travel speed, only moving time: {} km/h\".format(round(av_speed, 2)))\n",
    "\n",
    "    # Calculation of the average elevation\n",
    "    average_elevation = np.nanmean(my_mobility_data['elevation'])\n",
    "    print(\"Average elevation of track: {} m\".format(round(average_elevation,2)))\n",
    "\n",
    "    ################################ Plots ######################################\n",
    "    \n",
    "    # Travel speeds histogram\n",
    "    bin_size_speed = range(0, 100, 5)\n",
    "    # Plot a histrogram of the corrected speed data my_mobility_data[\"speed_corr\"]. Use the given bin size\n",
    "    # and set the argument 'desity=True' of the plt.hist() function.\n",
    "    # INSERT CODE HERE | BEGIN\n",
    "    #<<solution>>\n",
    "    fig, ax = plt.subplots(1, figsize=(8, 2))\n",
    "    ax.hist(my_mobility_data[\"speed_corr\"], bins=bin_size_speed, density=True)\n",
    "    #<</solution>>\n",
    "    # INSERT CODE HERE | END \n",
    "    ax.set_title(\"Histogram travel speeds\")\n",
    "    ax.set_ylabel(\"n Occurences\")\n",
    "    ax.set_xlabel(\"km/h bins\")\n",
    "\n",
    "    # Plot of elevation of the whole track\n",
    "    fig, ax = plt.subplots(1, figsize=(8, 2))\n",
    "    ax.plot(my_mobility_data['elevation'])\n",
    "    ax.set_title(\"Elevation of whole track\")\n",
    "    ax.set_ylabel(\"Altitude in m\")\n",
    "    ax.set_xlabel(\"time\")\n",
    "    \n",
    "    # Plot of corrected speed in comparision to moving averaged speed\n",
    "    #my_mobility_data[\"speed_ma\"]\n",
    "    fig, ax = plt.subplots(1, figsize=(8, 2))\n",
    "    ax.plot(my_mobility_data[\"speed_corr\"], marker=\".\", label=\"corr_speed\")\n",
    "    ax.plot(my_mobility_data[\"speed_ma\"], marker=\".\", label=\"speed_ma\")\n",
    "    ax.set_title(\"Corrected speed / moving averaged speed\")\n",
    "    ax.legend()\n",
    "    \n",
    "    return {\"av_speed\": av_speed, \"total_distance\": dis}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your function\n",
    "Use the function `statistical_kpis()` on the dataset `my_mobility_data_cont`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE | BEGIN\n",
    "#<<solution>>\n",
    "kpis_dict = statistical_kpis(my_mobility_data_cont)\n",
    "#<</solution>>\n",
    "# INSERT CODE HERE | END "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Popular Places\n",
    "\n",
    "To analyze the recorded mobility behavior, we need to cut the GPX-file into pieces, accordingly to actually travelled trips. One trip is therefore a movement from a point A to point B, where the subject stays a certain time at A resp. B. Before we can start looking for trips, we need to figure out, where our popular places are. To find out, we want to use ordinary [2D-histograms](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.hist2d.html) over lat/lon-bins of our whole track. By counting the numbers of GPS data-points in the location-bins, we can see where we have been to what extend of time. We use the dataset with continous time, so every row-entry represents the same amount of time.\n",
    "\n",
    "In the following, the functio `get_popular_places()` is given to obtain n popular places based on an input dataset.\n",
    "______________\n",
    "\n",
    "#### Signature of the function\n",
    "`gdf_hotspots_polygons = get_popular_places(my_mobility_data)`\n",
    "\n",
    "**Inputs**: \n",
    "* `my_mobility_data_cont`: Dataframe containing the trip\n",
    "* Optional\n",
    "    * `N_BIGGEST_HOTSPOTS`: Number of the most frequented bins to look for\n",
    "    * `FACTOR_BINSIZE`: Factor for calculation of real binsize\n",
    "    * `crs`: crs of returned GeoDataFrame\n",
    "\n",
    "**Returns**: `gdf_hotspots_polygons`: List containing GeoDataFrames with the N_BIGGEST_HOTSPOTS hotspots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import matplotlib.colors as mcolors\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry import box, Point\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "def get_popular_places(\n",
    "    my_mobility_data_cont, N_BIGGEST_HOTSPOTS = 20, FACTOR_BINSIZE = 8, crs = {'init': 'epsg:4326'}):\n",
    "        \n",
    "    # Calculating the range of latitude and longitude values \n",
    "    min_lat = min(my_mobility_data_cont.geometry.y)\n",
    "    max_lat = max(my_mobility_data_cont.geometry.y)\n",
    "    min_lon = min(my_mobility_data_cont.geometry.x)\n",
    "    max_lon = max(my_mobility_data_cont.geometry.x)\n",
    "    d_lat_km = geopy.distance.distance((min_lat,min_lon),(max_lat,min_lon)).kilometers\n",
    "    d_lon_km = geopy.distance.distance((min_lat,min_lon),(min_lat,max_lon)).kilometers\n",
    "    print(\"Latitude range:  {} - {}. {} km\".format(min_lat, max_lat, d_lat_km))\n",
    "    print(\"Longitude range: {} - {}. {} km\".format(min_lon, max_lon, d_lon_km))\n",
    "\n",
    "    # Binsize is based on the range of lat / lng and FACTOR_BINSIZE\n",
    "    # Higher FACTOR_BINSIZE means smaller bins \n",
    "    binsize = [int(d_lat_km * FACTOR_BINSIZE), int(d_lon_km * FACTOR_BINSIZE)]\n",
    "    print(\"Binsize is: {}\".format(binsize))\n",
    "    \n",
    "    # Use the plt.hist2d() function to plot a histogram with previously calculated binsize. This function \n",
    "    # returns a bi-dimensional histogram of samples x and y\n",
    "    fig, ax = plt.subplots(1)\n",
    "    pop_places_matrix = ax.hist2d(my_mobility_data_cont.geometry.y, my_mobility_data_cont.geometry.x,\n",
    "                                   bins=binsize, norm=mcolors.PowerNorm(0.1))\n",
    "    ax.set_title(\"Histogram lat/Lon, number of visists per bin\")\n",
    "    ax.set_ylabel(\"Longitude\")\n",
    "    ax.set_xlabel(\"Latitude\")\n",
    "    \n",
    "    # Find the N_BIGGEST_HOTSPOTS\n",
    "    hotspots = np.sort(pop_places_matrix[0].flatten())[-N_BIGGEST_HOTSPOTS:]\n",
    "\n",
    "    # Everything bigger or equal to the minimum of n_biggest_hotspots is consodered as a hotspot\n",
    "    THRESHOLD_HISTO_DYN = np.min(hotspots)\n",
    "    print(\"Threshold bins of interest: \", THRESHOLD_HISTO_DYN)\n",
    "\n",
    "    # Based on the found THRESHOLD_HISTO_DYN, we iterate over the matrix structure and identify the hotspot entries\n",
    "    gdf_hotspots_polygons = []\n",
    "    for i in range(0, pop_places_matrix[0].shape[0]):  \n",
    "        for j in range(0, pop_places_matrix[0].shape[1]): \n",
    "\n",
    "            if pop_places_matrix[0][i][j] >= THRESHOLD_HISTO_DYN:\n",
    "                print(\"Found {} at i={}, j={}\".format(pop_places_matrix[0][i][j], i, j))\n",
    "                lat1 = pop_places_matrix[1][i]\n",
    "                lat2 = pop_places_matrix[1][i+1]\n",
    "                lon1 = pop_places_matrix[2][j]\n",
    "                lon2 = pop_places_matrix[2][j+1]\n",
    "\n",
    "                circle = Point(abs(lon1+lon2)/2, abs(lat1+lat2)/2).buffer(0.002)\n",
    "\n",
    "                gdf_hotspots_polygons.append(\n",
    "                    gpd.GeoDataFrame({\"n_visits\": pop_places_matrix[0][i][j]},index=[0], crs=crs, geometry=[circle]))\n",
    "                \n",
    "    return gdf_hotspots_polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the given function\n",
    "Your task is now to obtain 20 popular places of the dataset `my_mobility_data_cont`. Use the given function `get_popular_places()` now to calculate popular places of the dataset `my_mobility_data_cont`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 20 most popular places \n",
    "gdf_hotspots_polygons = None\n",
    "# INSERT CODE HERE | BEGIN\n",
    "#<<solution>>\n",
    "gdf_hotspots_polygons = get_popular_places(my_mobility_data_cont)\n",
    "#<</solution>>\n",
    "# INSERT CODE HERE | END "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8 (given): Plot the polygons of the hot spots on the map\n",
    "Use the class `folium_plot` from Task 5 to plot the track and the polygons / circles on the map.\n",
    "* For the track, use again the function `add_to_folium()`\n",
    "* For the polygons / circles, iterate over the polygons list and use the `add_geojson_to_folium()` on each item\n",
    "\n",
    "The code for the task is already given. If the code doesnt run, make sure you put in the correct kind of input data from the previous task. You should see the total trip in red, and the hotspots marked as blueish ovals/circles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 8: Plot the polygons of the hot spots on the map\n",
    "m2 = folium_plot()\n",
    "\n",
    "m2.add_to_folium(my_mobility_data_cont)\n",
    "\n",
    "for idx, gdf_poly in enumerate(gdf_hotspots_polygons):\n",
    "    tooltip = \"Nr: {}. n_visits: {}\".format(idx, gdf_poly[\"n_visits\"][0])\n",
    "    m2.add_geojson_to_folium(gdf_poly.to_crs(epsg='4326').to_json(), tooltip)\n",
    "\n",
    "m2.save_map(\"polygons.html\")\n",
    "m2.show_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Find trips between the hotspots\n",
    "\n",
    "A core discipline in mobility data analysis is the detection of single trips between hotspots from a continous GPS-track. Now, we want to find the trips between the previously discovered hotspots and you should implement a trip detector methods as described in the following:\n",
    "\n",
    "Functions needed inside the detector:\n",
    "* Given: `polygons_contain_geometry(polygons, geometry)`\n",
    "* From Task 8: `total_distance()`\n",
    "\n",
    "Key logic of the algorithm:\n",
    "* We want to detect the start of a trip when we leave one of the hotspots\n",
    "* We want to detect the stop of a trip when we arrive in a hotspot and speed is close to zero\n",
    "* Record trips only, if they have a minimum length of 1 km\n",
    "\n",
    "| Control variable and init-value | Description |                                                                               \n",
    "|:--------------------------------|:------------------------------------------------------------------------------|\n",
    "| flag_start_track = False        | Flag to mark if track is started                                                               |\n",
    "| current_start_polygon = -1      | Index of the current start-polygon. returned from *polygons_contain_geometry()*                |\n",
    "| current_end_polygon = -1        | Index of the detected end-polygon. returned from *polygons_contain_geometry()*                 |\n",
    "| flag_left_start_polygon = None  | Equals to **False** when new track started. Flag set to **True** if we left the start-polygon. |\n",
    "| trips = []                      | List holding the detected trips                                                                |\n",
    "| counter_general = 0             | Counts every iteration of the for-loop. Index to the *my_mobility_data*                        \n",
    "\n",
    "<img src=\"images/loop trip detector.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "import time\n",
    "\n",
    "######################## Given ###########################################################################\n",
    "def polygons_contain_geometry(polygons, geometry):\n",
    "    '''\n",
    "    Function expects a list of gpd GeoDataframes, containing shapes. All df/shapes are tested, if the geometry\n",
    "    is inside it. \n",
    "    Parameters: \n",
    "    polygons: List of GeoDataFrames with geometry (polygon, circle...)\n",
    "    geometry: One GeoPandasDataFrame which is tested if it lies inside any of the geometry inside polygons\n",
    "    Return:\n",
    "    - idx: idx of the polygon which contains the geometry, -1 if no found\n",
    "    - is_inside: True, if containing polygon found, otherwise False\n",
    "    '''\n",
    "    if not isinstance(polygons, list):\n",
    "        raise \"ERROR: We need lists of gdf containing polygons!\"\n",
    "    \n",
    "    for idx, polygon in enumerate(polygons):\n",
    "        is_inside = polygon.geometry.contains(geometry.geometry)[0]\n",
    "        if is_inside:\n",
    "            #print(\"inside\", idx)\n",
    "            return is_inside, idx\n",
    "    else:\n",
    "        return False, -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of trip detector\n",
    "Implement the trip detector like shown in the diagram above. Please use the following set of control variables, which need to be initialized before starting into the loop. Run the detector on the dataset and plot the detected trips using the plotting classes function `add_many_to_folium()`. How many Trips do you find?\n",
    "\n",
    "**IMPORTANT NOTE:** The flow diagram above describes each step in detail and uses correct name spaces, it might be helfpul for you to open the diagram in a separate window and try to model the figure with the same syntax as given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Const MINIMUM_TRIP_LENGTH_KM\n",
    "MINIMUM_TRIP_LENGTH_KM = 1\n",
    "\n",
    "def trip_detector(my_mobility_data, gdf_hotspot_polygons):\n",
    "    \n",
    "    # Initialize controller variables before starting loop (same variable names as shown in the flow diagram)\n",
    "    flag_start_track=False\n",
    "    current_start_polygon=-1\n",
    "    current_end_polygon=-1\n",
    "    flag_left_start_polygon = None\n",
    "    trips = []\n",
    "    counter_general = 0  # counting the foor-loop runs, increment after every loop\n",
    "\n",
    "    \n",
    "    # Loop over the my_mobility_data\n",
    "    for idx, row in my_mobility_data.iterrows():\n",
    "        \n",
    "        # Check if current rows point lies inside a hotspot\n",
    "        is_inside, inside_idx = polygons_contain_geometry(gdf_hotspot_polygons, row)\n",
    "        \n",
    "        # 1. Find start point of trajectory ('Inside polygon and trip not started')\n",
    "        # If any mob_data point is within the polygon, we start looking for a trajectory.\n",
    "        # We do only so, if not started to look for one already (flag_start_trajectory)\n",
    "        if is_inside and not flag_start_track:\n",
    "            \n",
    "            # START TRIP\n",
    "            current_start_polygon = None \n",
    "            flag_left_start_polygon = None\n",
    "            flag_start_track = None\n",
    "            idx_start = None\n",
    "            # INSERT CODE HERE | BEGIN\n",
    "            #<<solution>>\n",
    "            current_start_polygon = inside_idx\n",
    "            flag_left_start_polygon = False\n",
    "            flag_start_track = True  # set flag to true: we follow a trajectory now\n",
    "            idx_start = counter_general  # memorize the start index of the current trajectory\n",
    "            #<</solution>>\n",
    "            # INSERT CODE HERE | END \n",
    "\n",
    "        # 2. Check if we already left one of the hotspots ('Check if we left hotspot')\n",
    "        # Hint: You need to insert a IF statement and if TRUE: 'Update Start Information' as \n",
    "        # described in the flow chart\n",
    "        \n",
    "        # INSERT CODE HERE | BEGIN\n",
    "        #<<solution>>\n",
    "        if is_inside == False and flag_left_start_polygon == False:\n",
    "            # Set the flag, that we left the start polygon\n",
    "            flag_left_start_polygon = True\n",
    "            # Also Reset the start-idx and the start time to the current -1\n",
    "            idx_start = counter_general-1\n",
    "        #<</solution>>\n",
    "        # INSERT CODE HERE | END \n",
    "                \n",
    "        # 3. Find end point of trajectory ('Check if we arrive in new hotspot')\n",
    "        # We want to check if the track goes inside the end_polygon. This can only happen after a minimum time\n",
    "        # and if we are inside a trajectory (flag_start_trajectory)\n",
    "        if is_inside and flag_start_track and flag_left_start_polygon == True:\n",
    "            \n",
    "            # 4. Set conditions to end trip ('End-conditions')\n",
    "            # Speed needs to be low 2 and we have been outside of hotspots (-1)\n",
    "            if row[\"speed_corr\"] < 2:\n",
    "                \n",
    "                current_end_polygon = inside_idx\n",
    "                flag_start_track = False  # we end the trajectory here\n",
    "                idx_end = counter_general  # memorize the end index of the current trajectory\n",
    "\n",
    "                # Slice trip\n",
    "                trip = my_mobility_data.iloc[idx_start:idx_end+1, :]  # slice the found trip from the whole dataset\n",
    "\n",
    "                # We only want to save the trip, 'if total_distance(trip) > MINIMUM_TRIP_LENGTH_KM'\n",
    "                # Hint: You might want to append a 'trip' to 'trips' if statement is true\n",
    "                # INSERT CODE HERE | BEGIN\n",
    "                #<<solution>>\n",
    "                if total_distance(trip) > MINIMUM_TRIP_LENGTH_KM:\n",
    "                    trips.append(trip)\n",
    "                #<</solution>>\n",
    "                # INSERT CODE HERE | END \n",
    "        \n",
    "        counter_general+=1\n",
    "    \n",
    "    return trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify trips\n",
    "Use the above implemented trip detector method `trip_detector()` to identify trips based on the dataset `my_mobility_data_cont` and the previously identifed hotspots `gdf_hotspots_polygons`. Plot these trips using the `folium_plot()` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the implemented trip detector 'trip_detector' to identify all trips between hotspots.\n",
    "trips = None\n",
    "# INSERT CODE HERE | BEGIN\n",
    "#<<solution>>\n",
    "trips = trip_detector(my_mobility_data_cont, gdf_hotspots_polygons)\n",
    "#<</solution>>\n",
    "# INSERT CODE HERE | END \n",
    "\n",
    "# How many trips can you identify?\n",
    "# INSERT CODE HERE | BEGIN\n",
    "#<<solution>>\n",
    "print(\"The dataset contains {} trips between hotspots.\".format(len(trips)))\n",
    "#<</solution>>\n",
    "# INSERT CODE HERE | END       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the trips and the hotspots\n",
    "m3 = folium_plot()\n",
    "m3.add_many_to_folium(trips)\n",
    "\n",
    "for idx, gdf_poly in enumerate(gdf_hotspots_polygons):\n",
    "    tooltip = \"Nr: {}. n_visits: {}\".format(idx, gdf_poly[\"n_visits\"][0])\n",
    "    m3.add_geojson_to_folium(gdf_poly, tooltip)\n",
    "\n",
    "m3.save_map(os.path.join('trips.html'))\n",
    "m3.show_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10 (given): Analyze the Trips using Reverse Geocoding\n",
    "\n",
    "#### Info\n",
    "Now we want to analyze the tracks a bit more detailed. As a tool, we can use the FTM GIS-API to perform reverse geocoding on our dataset. Therefore, we want to reverse-geocode the start- and end-position of all trips.\n",
    "\n",
    "Use the following sources: [Documentation GIS-API](https://wiki.tum.de/pages/viewpage.action?pageId=39591716) and [Python Requests to do HTTP-Requests](https://2.python-requests.org/en/master/)\n",
    "\n",
    "**IMPORTANT NOTE**: If you are doing this at home, GIS-API is only reachable from the university network. Use the LRZ-VPN.\n",
    "\n",
    "#### Task\n",
    "* Define a function, which takes all the trips and prints out a conclusing like the example below for every trip. Use the requests package to send a http-request containing the start resp. end-psoition of the track to the GIS-API and process the response.\n",
    "\n",
    "Print Example: <br>\n",
    "`---- Trip 0 Geocoding --------------------------------------------\n",
    "Start Time: 2019-07-31 16:22:51.722000+00:00\n",
    "Start address: TUM Fakultät Mathematik und Informatik, 3, Boltzmannstraße, Hochschul- und Forschungszentrum, Garching,Landkreis München, Obb, Bayern, 85748, Deutschland\n",
    "_-----\n",
    "End Time: 2019-07-31 17:05:51.722000+00:00\n",
    "End address: 6, Hörwarthstraße, Münchner Freiheit, Bezirksteil Münchner Freiheit, Stadtbezirk 04 Schwabing-West, München, Obb, Bayern, 80804, Deutschland\n",
    "_-------------------------------------------------------------------\n",
    "`\n",
    "\n",
    "* Run the function on the trips\n",
    "* Examine the result: Do you get meaningful information out of the API? Do you get reasonable start/end times?\n",
    "\n",
    "________________________\n",
    "\n",
    "#### Signature of the function\n",
    "`reverse_geocode(trips)`\n",
    "\n",
    "**Inputs**: `trips`: List of trips, each trip is a geoDataFrame\n",
    "\n",
    "**Returns**: No returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype: http://gis.ftm.mw.tum.de/reverse?coordinates=[11.62467, 48.2188]\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def reverse_geocode(trips):\n",
    "    \n",
    "    url = \"http://gis.ftm.mw.tum.de/reverse?coordinates={coordinate_list}\"\n",
    "\n",
    "    for idx, trip in enumerate(trips):\n",
    "        url_get_start = url.format(coordinate_list=str([trip.geometry[0].x, trip.geometry[0].y]))\n",
    "        url_get_end = url.format(coordinate_list=str([trip.geometry[-1].x, trip.geometry[-1].y]))\n",
    "\n",
    "        resp_start = requests.get(url=url_get_start)\n",
    "        resp_end = requests.get(url=url_get_end)\n",
    "\n",
    "        print(\"---- Trip {} Geocoding --------------------------------------------\".format(idx))\n",
    "        print(\"Start Time: {}\".format(trip[\"time\"][0]))\n",
    "        print(\"Start address: \", end=\"\")\n",
    "        print(json.loads(resp_start.text)[\"features\"][0][\"properties\"][\"display_name\"])\n",
    "        print(\"---\")\n",
    "        print(\"End Time: {}\".format(trip[\"time\"][-1]))\n",
    "        print(\"End address: \",end=\"\")\n",
    "        print(json.loads(resp_end.text)[\"features\"][0][\"properties\"][\"display_name\"])\n",
    "        print(\"-------------------------------------------------------------------\")\n",
    "    \n",
    "\n",
    "# Sort trips rising starttime\n",
    "trips = sorted(trips, key=lambda x:x[\"time\"][0])\n",
    "\n",
    "# Apply the reverse geocode function to the trips\n",
    "reverse_geocode(trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical KPIs of the single trips including map\n",
    "\n",
    "Use the function calculating the KPIs and the reverse geocoding in one step on every trip and examine the results. Additionally, plot each trip on a small folium map, to examine only the trip. Put everything in a loop and let it run over all your trips.\n",
    "\n",
    "**Hint:** You can call 'folium_plot()' as shown below to adjust the size and the center of the map of the map:\n",
    "\n",
    "`mx = folium_plot(width=\"50%\",height=\"200\", location=[lon, lat])`\n",
    "\n",
    "Answer these questions during the homework, of course you can already start to think :)  \n",
    "* Can you estimate the mode choice of every trip?\n",
    "* Can you find out about home / work place from the dataset?\n",
    "* Can you deduce free-time activities of the person tracked?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical KPIs of the single trips including map\n",
    "for idx, trip in enumerate(trips):\n",
    "    print(\"---- Trip {} ------------------------------------------------------\".format(idx))\n",
    "    mx = folium_plot(width=\"50%\",height=\"200\", location=[trip.geometry.y[int(len(trip.geometry)/2)], trip.geometry.x[int(len(trip.geometry)/2)]])\n",
    "    mx.add_to_folium(trip)\n",
    "    mx.add_marker_to_folium(lon=trip.geometry.y[0], lat=trip.geometry.x[1], popup=\"starttime: {}\".format(trip[\"time\"][0]))\n",
    "    display(mx.show_map())\n",
    "    \n",
    "    reverse_geocode([trip])\n",
    "    \n",
    "    statistical_kpis(trip)\n",
    "    print(\"------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If warning: too many open plots, run this cell to close all the open plots\n",
    "plt.close(\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
