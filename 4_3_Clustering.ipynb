{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-mean clustering\n",
    "How does k-mean clustering work?    \n",
    "Take a look at the animations from the links below.    \n",
    "http://tech.nitoyon.com/en/blog/2013/11/07/k-means/    \n",
    "https://www.learndatasci.com/tutorials/k-means-clustering-algorithms-python-intro/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T12:02:21.790244Z",
     "start_time": "2019-09-27T12:02:21.346748Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports for this notebook\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import time\n",
    "import mplleaflet\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "plt.style.use('ggplot')\n",
    "colors = ['r', 'g', 'b', 'y', 'c', 'm', 'r', 'g', 'b']\n",
    "\n",
    "# Euclidean Distance Caculator\n",
    "def dist(a, b, ax=1):\n",
    "    return np.linalg.norm(a - b, axis=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an interactive example of kmean clustering.    \n",
    "First we create some random sample data around three centers and plot them.    \n",
    "You can execute this multiple times to generate different datasets. Continue if your confident with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:38:16.468372Z",
     "start_time": "2019-09-18T06:38:16.437050Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set centers\n",
    "n_center = 3\n",
    "center= np.random.randn(n_center, 2)\n",
    "\n",
    "# Generate random data and center it to the three centers\n",
    "data = np.empty([1,2])\n",
    "for i in range(n_center):\n",
    "    data = np.append(data, np.random.randn(200, 2) + center[i,:], axis=0)\n",
    "\n",
    "data = pd.DataFrame(data=data[1:],\n",
    "            index=[i for i in range(data.shape[0]-1)],\n",
    "            columns=['x', 'y'])\n",
    "\n",
    "# Getting the values and plotting it\n",
    "f1 = data.x.values\n",
    "f2 = data.y.values\n",
    "X = np.array(list(zip(f1, f2)))\n",
    "fig, axes = plt.subplots()\n",
    "axes.scatter(f1, f2, c='black', s=7)\n",
    "axes.scatter(center[:,0],center[:,1], marker='o', s=200, c='r')\n",
    "fig.set_size_inches(8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try to find the centers of the random data by k-mean clustering.    \n",
    "We create three random points as start center of the clusters and will move them until the error is minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:38:19.489826Z",
     "start_time": "2019-09-18T06:38:19.457599Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of clusters\n",
    "k = 3\n",
    "# X coordinates of random centroids\n",
    "C_x = np.random.randint(np.min(X), np.max(X), size=k)\n",
    "# Y coordinates of random centroids\n",
    "C_y = np.random.randint(np.min(X), np.max(X), size=k)\n",
    "C = np.array(list(zip(C_x, C_y)), dtype=np.float32)\n",
    "# Plotting along with the Centroids\n",
    "fig, axes = plt.subplots()\n",
    "axes.scatter(f1, f2, c='#050505', s=7)\n",
    "axes.scatter(C_x, C_y, marker='o', s=200, c='g')\n",
    "fig.set_size_inches(8,8)\n",
    "\n",
    "# To store the value of centroids when it updates\n",
    "C_old = np.zeros(C.shape)\n",
    "# Cluster Lables(0, 1, 2)\n",
    "clusters = np.zeros(len(X))\n",
    "# Error func. - Distance between new centroids and old centroids\n",
    "error = dist(C, C_old, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This a kind of animated (replots every second). Execute the cell and watch the cluster centers mooving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:38:32.842877Z",
     "start_time": "2019-09-18T06:38:21.834567Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loop will run til the error becomes zero = centroids stop moving\n",
    "fig, ax = plt.subplots()\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "print(\"Error:\")\n",
    "#while error != 0: # automatic\n",
    "if True: # manual steps\n",
    "    #ax.clear()\n",
    "    # Assigning each value to its closest cluster\n",
    "    for i in range(len(X)):\n",
    "        distances = dist(X[i], C)\n",
    "        cluster = np.argmin(distances)\n",
    "        clusters[i] = cluster\n",
    "    # Storing the old centroid values\n",
    "    C_old = deepcopy(C)\n",
    "    # Finding the new centroids by taking the average value\n",
    "    for i in range(k):\n",
    "        points = [X[j] for j in range(len(X)) if clusters[j] == i]\n",
    "        C[i] = np.mean(points, axis=0)\n",
    "    \n",
    "    for i in range(k):\n",
    "        points = np.array([X[j] for j in range(len(X)) if clusters[j] == i])\n",
    "        ax.scatter(points[:, 0], points[:, 1], s=7, c=colors[i])\n",
    "        ax.scatter(C[:, 0], C[:, 1], marker='o', s=200, c='m')\n",
    "        ax.scatter(center[:,0],center[:,1], marker='o', s=200, c='r')\n",
    "        error = dist(C, C_old, None)\n",
    "    print(error)\n",
    "    fig.set_size_inches(10,10)\n",
    "    fig.canvas.draw()\n",
    "    #time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN Cluserting\n",
    "Have a look on the animation about how dbscan works    \n",
    "https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/\n",
    "\n",
    "## Road Accidents\n",
    "the geodataframe in accidents.p contains data from https://unfallatlas.statistikportal.de/_opendata.html     \n",
    "The data is already fimported and saved in the pickle file.\n",
    "Filter the data by acciedents where cars are involved (IstPKW) and try to find clusters.\n",
    "Try different settings for epsilon and the minimal number of points for a cluster. What generates the best results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T12:02:25.999370Z",
     "start_time": "2019-09-27T12:02:25.966671Z"
    }
   },
   "outputs": [],
   "source": [
    "import contextily as ctx\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "#from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_accidents = pd.read_pickle('data/accidents.p')\n",
    "display(df_accidents.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to add a contextily base map in the background\n",
    "\n",
    "#our coordinates are in epsg 4326\n",
    "# for correct basemap creation, they need to be in epsg 3857\n",
    "\n",
    "ST_TONER = 'http://tile.stamen.com/toner/{z}/{x}/{y}.png'\n",
    "ST_TONER_HYBRID = 'http://tile.stamen.com/toner-hybrid/{z}/{x}/{y}.png'\n",
    "ST_TONER_LABELS = 'http://tile.stamen.com/toner-labels/{z}/{x}/{y}.png'\n",
    "ST_TONER_LINES = 'http://tile.stamen.com/toner-lines/{z}/{x}/{y}.png'\n",
    "ST_TONER_BACKGROUND = 'http://tile.stamen.com/toner-background/{z}/{x}/{y}.png'\n",
    "ST_TONER_LITE = 'http://tile.stamen.com/toner-lite/{z}/{x}/{y}.png'\n",
    "\n",
    "def add_basemap(ax, zoom, source='http://tile.stamen.com/terrain/{z}/{x}/{y}.png'):\n",
    "    xmin, xmax, ymin, ymax = ax.axis()\n",
    "    basemap, extent = ctx.bounds2img(xmin, ymin, xmax, ymax, zoom=zoom, source=source)\n",
    "    ax.imshow(basemap, extent=extent, interpolation='bilinear')\n",
    "    # restore original x/y limits\n",
    "    ax.axis((xmin, xmax, ymin, ymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T12:04:03.178225Z",
     "start_time": "2019-09-27T12:04:02.638349Z"
    }
   },
   "outputs": [],
   "source": [
    "df_accidents['x'] = df_accidents.geometry.x\n",
    "df_accidents['y'] = df_accidents.geometry.y\n",
    "\n",
    "condition = df_accidents.IstPKW=='1'\n",
    "fdata = df_accidents[condition]\n",
    "X= fdata[['x', 'y']].to_numpy()\n",
    "#fdata.plot()\n",
    "\n",
    "# #############################################################################\n",
    "# Compute DBSCAN\n",
    "db = DBSCAN(eps=0.0010, min_samples=8).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "fig, ax = plt.subplots()\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = X[class_member_mask & core_samples_mask]\n",
    "    ax.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),markersize=5)\n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples_mask]\n",
    "    ax.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col), markersize=1)\n",
    "\n",
    "ax.set_title('Estimated number of clusters: %d' % n_clusters_)\n",
    "add_basemap(ax,15)\n",
    "#ctx.add_basemap(ax, crs = 4326); # not working anymore?\n",
    "ax.set_axis_off()\n",
    "fig.show()\n",
    "#mplleaflet.display(fig=fig, crs=df_accidents.crs) # alternative way to show points on map ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Try another clustering method: agglomerative clustering\n",
    "Implement agglomerative clustering for the same dataset. Try different settings for the linkage method.    \n",
    "See the referance for datails:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering     \n",
    "Try different parameters to find a good setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "treshold = 10 # number of points in cluster to be a relevant location\n",
    "cluster = AgglomerativeClustering(n_clusters = None, distance_threshold = 0.025, compute_full_tree= True, linkage = 'complete').fit(X)\n",
    "core_samples_mask = np.zeros_like(cluster.labels_, dtype=bool)\n",
    "#core_samples_mask[cluster.core_sample_indices_] = True\n",
    "labels = cluster.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "   # print(tuple(col))\n",
    "    #print()\n",
    "    if X[class_member_mask].size > treshold:\n",
    "\n",
    "        # middle of cluster\n",
    "        xy = X[class_member_mask].mean(axis=0)\n",
    "        ax.plot(xy[0], xy[1], 'o', markerfacecolor=tuple(col), markeredgecolor= tuple(col),markersize=15)\n",
    "\n",
    "        xy = X[class_member_mask & core_samples_mask]\n",
    "        ax.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col), markeredgecolor= tuple(col),markersize=5)\n",
    "\n",
    "        xy = X[class_member_mask & ~core_samples_mask]\n",
    "        ax.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col), markeredgecolor= tuple(col), markersize=3)\n",
    "\n",
    "ax.set_title('Estimated number of clusters: %d' % n_clusters_)\n",
    "add_basemap(ax,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
